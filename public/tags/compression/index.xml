<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Compression on EETH - Blog</title>
    <link>https://eeth.pages.dev/tags/compression/</link>
    <description>Recent content in Compression on EETH - Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <managingEditor>jayeshjoshi08jj@gmail.com (hkcfs)</managingEditor>
    <webMaster>jayeshjoshi08jj@gmail.com (hkcfs)</webMaster>
    <copyright>hkcfs</copyright>
    <lastBuildDate>Wed, 09 Oct 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://eeth.pages.dev/tags/compression/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>The Best Compression Algo Maybe</title>
      <link>https://eeth.pages.dev/blog/the-best-compression-algo-maybe/</link>
      <pubDate>Wed, 09 Oct 2024 00:00:00 +0000</pubDate><author>jayeshjoshi08jj@gmail.com (hkcfs)</author>
      <guid>https://eeth.pages.dev/blog/the-best-compression-algo-maybe/</guid>
      <description>&lt;h2 id=&#34;compression-algorithms-the-unsung-heroes-of-the-internet&#34;&gt;&lt;strong&gt;Compression Algorithms: The Unsung Heroes of the Internet&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;Compression algorithms are the silent workhorses that made the internet boom of the 1990s possible. They enabled pirates to download gigabytes of data squeezed into mere megabytes, albeit with a tradeoff: higher electricity bills during decompression or the patience to wait as files unraveled byte by byte.&lt;/p&gt;&#xA;&lt;p&gt;In modern times, compression is often overlooked. Storage is dirt cheap, and bandwidth feels limitless for most of us. Yet, compression remains invaluable, particularly in data centers and archival zones where storage efficiency takes precedence over speed. It’s no coincidence that popular filesystems like Btrfs, NTFS, and ZFS have built-in compression features. These tools may take a few extra seconds during operation, but they can save organizations thousands of dollars in hard drives or SSDs—a worthy trade-off if you ask me.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<h2 id="compression-algorithms-the-unsung-heroes-of-the-internet"><strong>Compression Algorithms: The Unsung Heroes of the Internet</strong></h2>
<p>Compression algorithms are the silent workhorses that made the internet boom of the 1990s possible. They enabled pirates to download gigabytes of data squeezed into mere megabytes, albeit with a tradeoff: higher electricity bills during decompression or the patience to wait as files unraveled byte by byte.</p>
<p>In modern times, compression is often overlooked. Storage is dirt cheap, and bandwidth feels limitless for most of us. Yet, compression remains invaluable, particularly in data centers and archival zones where storage efficiency takes precedence over speed. It’s no coincidence that popular filesystems like Btrfs, NTFS, and ZFS have built-in compression features. These tools may take a few extra seconds during operation, but they can save organizations thousands of dollars in hard drives or SSDs—a worthy trade-off if you ask me.</p>
<p>But the story today is different. We’ve moved past the era of efficient, practical compression. Now, the pursuit is maximum compression, no matter how long it takes. Shrinking gigabytes of data into a few tens of megabytes is the name of the game. Enter <strong>cmix</strong>.</p>
<hr>
<h2 id="compression-today-maximum-over-practicality"><strong>Compression Today: Maximum Over Practicality</strong></h2>
<p>Today’s story is different. We’re less interested in efficient, fast compression and more focused on achieving <em>maximum</em> compression ratios. Who cares if it takes seven days to compress a file, as long as we shrink gigabytes of data into a few tens of megabytes? That’s where <strong>cmix</strong> comes in.</p>
<p><a href="https://www.byronknoll.com/cmix.html">cmix</a> is a lossless data compression program designed to achieve exceptional compression ratios at the cost of extreme CPU and memory usage. It consistently achieves state-of-the-art results, as seen in benchmarks like the <a href="https://www.mattmahoney.net/dc/text.html">Large Text Compression Benchmark</a> by Matt Mahoney. cmix earned second place, just behind <strong>nncp v3.2</strong>.</p>
<p>Here’s the trade-off: cmix is <em>not</em> fast or memory efficient. For instance, in the benchmark:</p>
<ul>
<li><strong>nncp v3.2</strong> (1st place) took 241,871 seconds and used 7.6 GB of RAM.</li>
<li><strong>cmix</strong> (2nd place) took 622,949 seconds and consumed 30.95 GB of RAM.</li>
</ul>
<p>While cmix isn’t practical for day-to-day use, it’s an exciting tool for anyone exploring extreme compression.</p>
<hr>
<h2 id="setting-up-cmix"><strong>Setting Up cmix</strong></h2>
<p>Installing cmix is straightforward, though some adjustments may be needed depending on your system.</p>
<h3 id="hardware-and-os-specs"><strong>Hardware and OS Specs</strong></h3>
<p>For testing, I used the following setup:</p>





<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="ln">1</span><span class="cl">OS: Ubuntu 22.04.5 LTS x86_64
</span></span><span class="line"><span class="ln">2</span><span class="cl">Host: Google Compute Engine
</span></span><span class="line"><span class="ln">3</span><span class="cl">Kernel: 6.1.91-060191-generic
</span></span><span class="line"><span class="ln">4</span><span class="cl">CPU: AMD EPYC 7B13 <span class="o">(</span>16<span class="o">)</span> @ 2.449GHz
</span></span><span class="line"><span class="ln">5</span><span class="cl">Memory: 37054MiB / 64297MiB</span></span></code></pre></div><h3 id="installation-steps"><strong>Installation Steps</strong></h3>





<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="ln">1</span><span class="cl">sudo apt update
</span></span><span class="line"><span class="ln">2</span><span class="cl">sudo apt install git
</span></span><span class="line"><span class="ln">3</span><span class="cl">git clone https://github.com/byronknoll/cmix
</span></span><span class="line"><span class="ln">4</span><span class="cl"><span class="nb">cd</span> cmix
</span></span><span class="line"><span class="ln">5</span><span class="cl">make</span></span></code></pre></div><p>If you’re lucky, this will work flawlessly. If not, here’s what I had to do to get it running on Ubuntu 22.04.5 LTS.</p>
<ol>
<li>Install dependencies:





<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="ln">1</span><span class="cl">sudo apt install clang libc++-dev</span></span></code></pre></div></li>
<li>Modify the <code>Makefile</code>:





<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-diff" data-lang="diff"><span class="line"><span class="ln">1</span><span class="cl"><span class="gd">- CC = clang++-17
</span></span></span><span class="line"><span class="ln">2</span><span class="cl"><span class="gd"></span><span class="gi">+ CC = clang++
</span></span></span><span class="line"><span class="ln">3</span><span class="cl"><span class="gi"></span><span class="gd">- all: LFLAGS += -Ofast -march=native
</span></span></span><span class="line"><span class="ln">4</span><span class="cl"><span class="gd"></span><span class="gi">+ all: LFLAGS += -O3 -ffast-math -march=native
</span></span></span></code></pre></div></li>
<li>Recompile:





<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="ln">1</span><span class="cl">make</span></span></code></pre></div></li>
</ol>
<p>If everything works, you can run <code>./cmix --help</code> which should give you:</p>





<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="ln"> 1</span><span class="cl">cmix version <span class="m">21</span>
</span></span><span class="line"><span class="ln"> 2</span><span class="cl">Compress:
</span></span><span class="line"><span class="ln"> 3</span><span class="cl">    with dictionary:    cmix -c <span class="o">[</span>dictionary<span class="o">]</span> <span class="o">[</span>input<span class="o">]</span> <span class="o">[</span>output<span class="o">]</span>
</span></span><span class="line"><span class="ln"> 4</span><span class="cl">    without dictionary: cmix -c <span class="o">[</span>input<span class="o">]</span> <span class="o">[</span>output<span class="o">]</span>
</span></span><span class="line"><span class="ln"> 5</span><span class="cl">    force text-mode:    cmix -t <span class="o">[</span>dictionary<span class="o">]</span> <span class="o">[</span>input<span class="o">]</span> <span class="o">[</span>output<span class="o">]</span>
</span></span><span class="line"><span class="ln"> 6</span><span class="cl">    no preprocessing:   cmix -n <span class="o">[</span>input<span class="o">]</span> <span class="o">[</span>output<span class="o">]</span>
</span></span><span class="line"><span class="ln"> 7</span><span class="cl">    only preprocessing: cmix -s <span class="o">[</span>dictionary<span class="o">]</span> <span class="o">[</span>input<span class="o">]</span> <span class="o">[</span>output<span class="o">]</span>
</span></span><span class="line"><span class="ln"> 8</span><span class="cl">                        cmix -s <span class="o">[</span>input<span class="o">]</span> <span class="o">[</span>output<span class="o">]</span>
</span></span><span class="line"><span class="ln"> 9</span><span class="cl">Decompress:
</span></span><span class="line"><span class="ln">10</span><span class="cl">    with dictionary:    cmix -d <span class="o">[</span>dictionary<span class="o">]</span> <span class="o">[</span>input<span class="o">]</span> <span class="o">[</span>output<span class="o">]</span>
</span></span><span class="line"><span class="ln">11</span><span class="cl">    without dictionary: cmix -d <span class="o">[</span>input<span class="o">]</span> <span class="o">[</span>output<span class="o">]</span></span></span></code></pre></div><hr>
<h2 id="testing-cmix-bee-movie-script"><strong>Testing cmix: Bee Movie Script</strong></h2>
<p>To test cmix, I used the <em>Bee Movie</em> script. Here are the results:</p>
<h3 id="original-file"><strong>Original File</strong></h3>
<ul>
<li>File Size: <strong>86,091 bytes</strong> (~85 KB)</li>
</ul>
<h3 id="compressed-file-cmix"><strong>Compressed File (cmix)</strong></h3>
<ul>
<li>File Size: <strong>21,966 bytes</strong> (~22 KB)</li>
<li>Time Taken: <strong>124.65 seconds</strong></li>
</ul>
<p><img src="/images/btop-bee-movie.jpg" alt="System resource usage displayed using btop, showing one CPU core usage at 100%, 13.9GB of RAM used by the “cmix” process, and an average CPU usage of 25% for that process for compressing the BEE movie Script."></p>
<p>Command:</p>





<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="ln">1</span><span class="cl">./cmix -c bee-movie.txt bee-movie.txt.cmix
</span></span><span class="line"><span class="ln">2</span><span class="cl">Detected block types: TEXT: 100.0%
</span></span><span class="line"><span class="ln">3</span><span class="cl"><span class="m">86091</span> bytes -&gt; <span class="m">21966</span> bytes in 124.65 s.
</span></span><span class="line"><span class="ln">4</span><span class="cl">cross entropy: 2.041
</span></span><span class="line"><span class="ln">5</span><span class="cl">
</span></span><span class="line"><span class="ln">6</span><span class="cl">it took 124.65 s.</span></span></code></pre></div><p>Repeated trials brought the time down slightly (108.77 seconds), but it’s still not “fast.” For comparison, I tested other algorithms:</p>
<table>
  <thead>
      <tr>
          <th><strong>Algorithm</strong></th>
          <th><strong>Compressed Size (bytes)</strong></th>
          <th><strong>Time Taken</strong></th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>gzip</td>
          <td>33,765</td>
          <td>~0.5s</td>
      </tr>
      <tr>
          <td>xz</td>
          <td>31,100</td>
          <td>~0.5s</td>
      </tr>
      <tr>
          <td>zstd (level 22)</td>
          <td>31,639</td>
          <td>~0.5s</td>
      </tr>
      <tr>
          <td>zpaq</td>
          <td>25,195</td>
          <td>~0.8s</td>
      </tr>
      <tr>
          <td><strong>cmix</strong></td>
          <td><strong>21,966</strong></td>
          <td><strong>124.65s</strong></td>
      </tr>
  </tbody>
</table>
<p>While cmix achieves the best compression, its time and resource demands are immense.</p>
<hr>
<h2 id="compressing-the-linux-kernel"><strong>Compressing the Linux Kernel</strong></h2>
<p>For a tougher test, I attempted to compress the original Linux 1.0 source code (released on March 13, 1994). Here are the numbers:</p>
<table>
  <thead>
      <tr>
          <th><strong>File</strong></th>
          <th><strong>Size (bytes)</strong></th>
          <th><strong>Time Taken</strong></th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>Original</td>
          <td>5171200 (5.0M)</td>
          <td>-</td>
      </tr>
      <tr>
          <td>gzip</td>
          <td>1259175 (1.3M)</td>
          <td>~0.308s</td>
      </tr>
      <tr>
          <td>xz</td>
          <td>935892 (914K)</td>
          <td>~2.895s</td>
      </tr>
      <tr>
          <td>zstd</td>
          <td>697924 (682K)</td>
          <td>~16.73s</td>
      </tr>
      <tr>
          <td><strong>cmix</strong></td>
          <td><strong>516406 (505K)</strong></td>
          <td><strong>7441.04s (131m34.256s)</strong></td>
      </tr>
  </tbody>
</table>
<p><img src="/images/btop-linux-kernel.jpg" alt="The system load shown using btop having cpu at around 60% load, with 16 GB of ram used up by cmix with an average cpu usage of 25% while compressing the linux 1.0 Kernel"></p>





<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="ln"> 1</span><span class="cl"><span class="nb">time</span> ./cmix -c ../linux-1.0.tar ../linux-1.0.tar.cmix
</span></span><span class="line"><span class="ln"> 2</span><span class="cl">Detected block types: TEXT: 91.3% DEFAULT: 8.7%
</span></span><span class="line"><span class="ln"> 3</span><span class="cl">progress: 12.32%
</span></span><span class="line"><span class="ln"> 4</span><span class="cl">progress: 20.16%
</span></span><span class="line"><span class="ln"> 5</span><span class="cl"><span class="m">5171200</span> bytes -&gt; <span class="m">516406</span> bytes in 7441.04 s.
</span></span><span class="line"><span class="ln"> 6</span><span class="cl">cross entropy: 0.799
</span></span><span class="line"><span class="ln"> 7</span><span class="cl">
</span></span><span class="line"><span class="ln"> 8</span><span class="cl">real    131m34.256s
</span></span><span class="line"><span class="ln"> 9</span><span class="cl">user    121m12.508s
</span></span><span class="line"><span class="ln">10</span><span class="cl">sys     2m52.326s</span></span></code></pre></div><p>I initially planned to test the Linux 6.12.3 tarball (1.54 GB), but cmix proved impractical, taking over 9 minutes to reach just 0.01% progress. Even older versions like Linux 2.5 took too long. This highlights cmix’s limitations with large files.</p>
<hr>
<h2 id="final-thoughts"><strong>Final Thoughts</strong></h2>
<p>Despite its impracticality for everyday use, cmix holds a special place in my heart. It was the first program I compiled while working on my project, <strong>osqr</strong>, and exploring its potential was both fun and enlightening. Compression may feel like a relic of the past, but tools like cmix remind us of the art and science behind squeezing data to its absolute minimum.</p>
<p>If nothing else, cmix is a testament to how far we can push the limits of lossless compression. It may not be practical, but it’s a lot of fun.</p>
<p>What are your thoughts on cmix and other compression algorithms? Let me know below!</p>
]]></content:encoded>
    </item>
  </channel>
</rss>
